{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d26b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dependencies import *\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c522ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs\n",
    "precip_input= xr.open_dataset (\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/RhiresD_1km_bicubic_Swiss_features_masked.nc\")\n",
    "temp_input= xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/TabsD_1km_bicubic_Swiss_features_masked.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09450d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets\n",
    "precip_target= xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/raw/RhiresD_1971_2022.nc\")\n",
    "temp_target= xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/raw/TabsD_1971_2022.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111d7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buildign a pytorch dataset with these inputs and targets \n",
    "from torch.utils.data import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef46ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downscaling_Dataset(Dataset):\n",
    "    def __init__(self, input_ds, target_ds, var_name_inputs, var_name_targets, transform=None):\n",
    "        \"\"\"Takes in xarray datasets as inputs for both inputs and tagrets, var_name is for variable name inside the dataset, and transform is for any preprocessing in case it is done\"\"\"\n",
    "\n",
    "        self.input = input_ds[var_name_inputs]\n",
    "        self.target = target_ds[var_name_targets]\n",
    "        self.transform= transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the length of the dataset, which is the number of timesteps in the input/target inputs\"\"\"\n",
    "        return len(self.input.time)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Returns the pair of input and target data for a given index\"\"\"\n",
    "        input_img= self.input.isel(time=index).values\n",
    "        target_img= self.target.isel(time=index).values\n",
    "\n",
    "        #Channel dimension for the input and ther target \n",
    "        input_img= torch.tensor(input_img).unsqueeze(0).float()\n",
    "        target_img= torch.tensor(target_img).unsqueeze(0).float()\n",
    "\n",
    "        #If any transform is provided , else transform is None by default\n",
    "        if self.transform:\n",
    "            input_img= self.transform(input_img)\n",
    "            target_img= self.transform(target_img)\n",
    "\n",
    "         #Returnig  the input targhet pairs   \n",
    "        return input_img, target_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f807a9c4",
   "metadata": {},
   "source": [
    "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021c8e63",
   "metadata": {},
   "source": [
    "###Normalisation code: To be written later as required "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38ff183",
   "metadata": {},
   "source": [
    "Max min scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c154dc1",
   "metadata": {},
   "source": [
    "xxxxxxxxxxxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28647c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the full dataset and then splitting it into train, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46c57b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_precip_dataset= Downscaling_Dataset(precip_input, precip_target, \"pr\",\"RhiresD\", transform=None)\n",
    "torch_temp_dataset= Downscaling_Dataset(temp_input, temp_target, \"tas\",\"TabsD\", transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28be0fc",
   "metadata": {},
   "source": [
    "We will do spatial and temporal cross validation later for different cases. For now, for each decade, 70% testing, 30 percent eval, 10 percent testing . No shiffling between decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e89e76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce198623",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "#Reading the time coordinate\n",
    "times = precip_input['time'].values\n",
    "times = pd.to_datetime(times)  \n",
    "\n",
    "# Map samples to decades\n",
    "def get_decade(year):\n",
    "    return int(year // 10 * 10)\n",
    "\n",
    "decades = [get_decade(t.year) for t in times]\n",
    "\n",
    "# Indices for each decade\n",
    "decade_to_indices = defaultdict(list)\n",
    "for idx, decade in enumerate(decades):\n",
    "    decade_to_indices[decade].append(idx)\n",
    "\n",
    "# Split within each decade\n",
    "train_indices = []\n",
    "val_indices = []\n",
    "test_indices = []\n",
    "\n",
    "for decade, indices in decade_to_indices.items():\n",
    "    indices = torch.tensor(indices)\n",
    "    indices = indices[torch.randperm(len(indices))]\n",
    "\n",
    "    n_total = len(indices)\n",
    "    n_train = int(0.7 * n_total)\n",
    "    n_val = int(0.2 * n_total)\n",
    "    n_test = n_total - n_train - n_val  # whatever is left goes into testing\n",
    "\n",
    "    train_indices.append(indices[:n_train])\n",
    "    val_indices.append(indices[n_train:n_train + n_val])\n",
    "    test_indices.append(indices[n_train + n_val:])\n",
    "\n",
    "# Concatenate all decades\n",
    "train_indices = torch.cat(train_indices)\n",
    "val_indices = torch.cat(val_indices)\n",
    "test_indices = torch.cat(test_indices)\n",
    "\n",
    "# Subset the datasets\n",
    "precip_train = Subset(torch_precip_dataset, train_indices)\n",
    "precip_val = Subset(torch_precip_dataset, val_indices)\n",
    "precip_test = Subset(torch_precip_dataset, test_indices)\n",
    "\n",
    "temp_train = Subset(torch_temp_dataset, train_indices)\n",
    "temp_val = Subset(torch_temp_dataset, val_indices)\n",
    "temp_test = Subset(torch_temp_dataset, test_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63cfd4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 265, 370]) torch.Size([1, 265, 370])\n"
     ]
    }
   ],
   "source": [
    "x_precip, y_precip= precip_train[0]\n",
    "x_temp, y_temp= temp_train[0]\n",
    "print(x_precip.shape, y_precip.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a989f0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 265, 370]) torch.Size([1, 265, 370])\n"
     ]
    }
   ],
   "source": [
    "print(x_temp.shape, y_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c73c8b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paired(Dataset):\n",
    "    def __init__(self, precip_dataset, temp_dataset):\n",
    "        assert len(precip_dataset) == len(temp_dataset), \"Datasets must be the same length.\"\n",
    "        self.precip_dataset = precip_dataset\n",
    "        self.temp_dataset = temp_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.precip_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        precip_input, precip_target = self.precip_dataset[idx]\n",
    "        temp_input, temp_target = self.temp_dataset[idx]\n",
    "\n",
    "        # Stack input channels together (pr, tas)\n",
    "        input_combined = torch.cat([precip_input, temp_input], dim=0)  # Shape: (2, H, W)\n",
    "\n",
    "        # Stack output/target channels together (pr_target, tas_target)\n",
    "        target_combined = torch.cat([precip_target, temp_target], dim=0)  # Shape: (2, H, W)\n",
    "\n",
    "        return input_combined, target_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be2cc7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = Paired(precip_train, temp_train)\n",
    "val_dataset = Paired(precip_val, temp_val)\n",
    "test_dataset = Paired(precip_test, temp_test)\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73ec9bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/models/\")\n",
    "from UNet import UNet\n",
    "\n",
    "model_01_experimental = UNet(in_channels=2, out_channels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c77cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_01_experimental.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60434e34",
   "metadata": {},
   "source": [
    "xxxxxxxxxxxxxxxxxxxxxxxxxxTraining Loop xxxxxxxxxxxxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7970406e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[32m      8\u001b[39m     optimizer.zero_grad()\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     outputs = \u001b[43mmodel_01_experimental\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m     10\u001b[39m     loss = criterion(outputs, targets)\n\u001b[32m     11\u001b[39m     loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/models/UNet.py:103\u001b[39m, in \u001b[36mUNet.forward\u001b[39m\u001b[34m(self, inputs, targets)\u001b[39m\n\u001b[32m     99\u001b[39m b= \u001b[38;5;28mself\u001b[39m.bottleneck(p4)\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m###Decoder###\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m d1= \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mDecoder1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms4\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m d2= \u001b[38;5;28mself\u001b[39m.Decoder2(d1, s3)\n\u001b[32m    105\u001b[39m d3= \u001b[38;5;28mself\u001b[39m.Decoder3(d2, s2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/models/UNet.py:48\u001b[39m, in \u001b[36mDecoder_Block.forward\u001b[39m\u001b[34m(self, inputs, skip)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, skip):\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mup\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.shape[\u001b[32m2\u001b[39m:] != skip.shape[\u001b[32m2\u001b[39m:]:\n\u001b[32m     50\u001b[39m         x = torch.nn.functional.interpolate(x, size=skip.shape[\u001b[32m2\u001b[39m:], mode=\u001b[33m'\u001b[39m\u001b[33mbilinear\u001b[39m\u001b[33m'\u001b[39m, align_corners=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162\u001b[39m, in \u001b[36mConvTranspose2d.forward\u001b[39m\u001b[34m(self, input, output_size)\u001b[39m\n\u001b[32m   1151\u001b[39m num_spatial_dims = \u001b[32m2\u001b[39m\n\u001b[32m   1152\u001b[39m output_padding = \u001b[38;5;28mself\u001b[39m._output_padding(\n\u001b[32m   1153\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1154\u001b[39m     output_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1159\u001b[39m     \u001b[38;5;28mself\u001b[39m.dilation,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   1160\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv_transpose2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_padding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10  \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_01_experimental.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_01_experimental(inputs, targets)  # Forward pass\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.3f}\")\n",
    "    # Validation step\n",
    "    model_01_experimental.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            outputs = model_01_experimental(inputs)\n",
    "            val_loss += criterion(outputs, targets).item()\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Val Loss: {val_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27811f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test flag\n",
    "quick_test = True\n",
    "\n",
    "# Adjust dataset and loader for quick testing\n",
    "if quick_test:\n",
    "    # Use a small subset of the dataset\n",
    "    small_train_loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.Subset(train_dataset, range(100)),\n",
    "        batch_size=32,\n",
    "        shuffle=True\n",
    "    )\n",
    "    small_val_loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.Subset(val_dataset, range(50)),\n",
    "        batch_size=32,\n",
    "        shuffle=False\n",
    "    )\n",
    "    train_loader = small_train_loader\n",
    "    val_loader = small_val_loader\n",
    "    num_epochs = 1  # Only one epoch for testing\n",
    "else:\n",
    "    # Use the full dataset\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    num_epochs = 10  # or your desired number of epochs\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model_01_experimental.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_01_experimental(inputs, targets)  # Forward pass (pass targets for resizing safety)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        if quick_test and i == 2:  # Stop after 3 batches during quick test\n",
    "            break\n",
    "\n",
    "    train_loss /= (i + 1)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.3f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model_01_experimental.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for j, (inputs, targets) in enumerate(val_loader):\n",
    "            outputs = model_01_experimental(inputs)  # No targets during validation\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            if quick_test and j == 2:\n",
    "                break\n",
    "\n",
    "    val_loss /= (j + 1)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Val Loss: {val_loss:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
