{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d26b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dependencies import *\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c522ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs\n",
    "precip_input= xr.open_dataset (\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/RhiresD_1km_bicubic_Swiss_features_masked.nc\")\n",
    "temp_input= xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/TabsD_1km_bicubic_Swiss_features_masked.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09450d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets\n",
    "precip_target= xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/raw/RhiresD_1971_2022.nc\")\n",
    "temp_target= xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/raw/TabsD_1971_2022.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111d7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buildign a pytorch dataset with these inputs and targets \n",
    "from torch.utils.data import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef46ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downscaling_Dataset(Dataset):\n",
    "    def __init__(self, input_ds, target_ds, var_name_inputs, var_name_targets, transform=None):\n",
    "        \"\"\"Takes in xarray datasets as inputs for both inputs and tagrets, var_name is for variable name inside the dataset, and transform is for any preprocessing in case it is done\"\"\"\n",
    "\n",
    "        self.input = input_ds[var_name_inputs]\n",
    "        self.target = target_ds[var_name_targets]\n",
    "        self.transform= transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the length of the dataset, which is the number of timesteps in the input/target inputs\"\"\"\n",
    "        return len(self.input.time)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Returns the pair of input and target data for a given index\"\"\"\n",
    "        input_img= self.input.isel(time=index).values\n",
    "        target_img= self.target.isel(time=index).values\n",
    "\n",
    "        #Channel dimension for the input and ther target \n",
    "        input_img= torch.tensor(input_img).unsqueeze(0).float()\n",
    "        target_img= torch.tensor(target_img).unsqueeze(0).float()\n",
    "\n",
    "        #If any transform is provided , else transform is None by default\n",
    "        if self.transform:\n",
    "            input_img= self.transform(input_img)\n",
    "            target_img= self.transform(target_img)\n",
    "\n",
    "         #Returnig  the input targhet pairs   \n",
    "        return input_img, target_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f807a9c4",
   "metadata": {},
   "source": [
    "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021c8e63",
   "metadata": {},
   "source": [
    "###Normalisation code: To be written later as required "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38ff183",
   "metadata": {},
   "source": [
    "Max min scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c154dc1",
   "metadata": {},
   "source": [
    "xxxxxxxxxxxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28647c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the full dataset and then splitting it into train, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46c57b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_precip_dataset= Downscaling_Dataset(precip_input, precip_target, \"pr\",\"RhiresD\", transform=None)\n",
    "torch_temp_dataset= Downscaling_Dataset(temp_input, temp_target, \"tas\",\"TabsD\", transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28be0fc",
   "metadata": {},
   "source": [
    "We will do spatial and temporal cross validation later for different cases. For now, for each decade, 70% testing, 30 percent eval, 10 percent testing . No shiffling between decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e89e76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce198623",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "#Reading the time coordinate\n",
    "times = precip_input['time'].values\n",
    "times = pd.to_datetime(times)  \n",
    "\n",
    "# Map samples to decades\n",
    "def get_decade(year):\n",
    "    return int(year // 10 * 10)\n",
    "\n",
    "decades = [get_decade(t.year) for t in times]\n",
    "\n",
    "# Indices for each decade\n",
    "decade_to_indices = defaultdict(list)\n",
    "for idx, decade in enumerate(decades):\n",
    "    decade_to_indices[decade].append(idx)\n",
    "\n",
    "# Split within each decade\n",
    "train_indices = []\n",
    "val_indices = []\n",
    "test_indices = []\n",
    "\n",
    "for decade, indices in decade_to_indices.items():\n",
    "    indices = torch.tensor(indices)\n",
    "    indices = indices[torch.randperm(len(indices))]\n",
    "\n",
    "    n_total = len(indices)\n",
    "    n_train = int(0.7 * n_total)\n",
    "    n_val = int(0.2 * n_total)\n",
    "    n_test = n_total - n_train - n_val  # whatever is left goes into testing\n",
    "\n",
    "    train_indices.append(indices[:n_train])\n",
    "    val_indices.append(indices[n_train:n_train + n_val])\n",
    "    test_indices.append(indices[n_train + n_val:])\n",
    "\n",
    "# Concatenate all decades\n",
    "train_indices = torch.cat(train_indices)\n",
    "val_indices = torch.cat(val_indices)\n",
    "test_indices = torch.cat(test_indices)\n",
    "\n",
    "# Subset the datasets\n",
    "precip_train = Subset(torch_precip_dataset, train_indices)\n",
    "precip_val = Subset(torch_precip_dataset, val_indices)\n",
    "precip_test = Subset(torch_precip_dataset, test_indices)\n",
    "\n",
    "temp_train = Subset(torch_temp_dataset, train_indices)\n",
    "temp_val = Subset(torch_temp_dataset, val_indices)\n",
    "temp_test = Subset(torch_temp_dataset, test_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63cfd4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 265, 370]) torch.Size([1, 265, 370])\n"
     ]
    }
   ],
   "source": [
    "x_precip, y_precip= precip_train[0]\n",
    "x_temp, y_temp= temp_train[0]\n",
    "print(x_precip.shape, y_precip.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a989f0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 265, 370]) torch.Size([1, 265, 370])\n"
     ]
    }
   ],
   "source": [
    "print(x_temp.shape, y_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c73c8b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paired(Dataset):\n",
    "    def __init__(self, precip_dataset, temp_dataset):\n",
    "        assert len(precip_dataset) == len(temp_dataset), \"Datasets must be the same length.\"\n",
    "        self.precip_dataset = precip_dataset\n",
    "        self.temp_dataset = temp_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.precip_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        precip_input, precip_target = self.precip_dataset[idx]\n",
    "        temp_input, temp_target = self.temp_dataset[idx]\n",
    "\n",
    "        # Stack input channels together (pr, tas)\n",
    "        input_combined = torch.cat([precip_input, temp_input], dim=0)  # Shape: (2, H, W)\n",
    "\n",
    "        # Stack output/target channels together (pr_target, tas_target)\n",
    "        target_combined = torch.cat([precip_target, temp_target], dim=0)  # Shape: (2, H, W)\n",
    "\n",
    "        return input_combined, target_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be2cc7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = Paired(precip_train, temp_train)\n",
    "val_dataset = Paired(precip_val, temp_val)\n",
    "test_dataset = Paired(precip_test, temp_test)\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73ec9bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/models/\")\n",
    "from UNet import UNet\n",
    "\n",
    "model_01_experimental = UNet(in_channels=2, out_channels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c77cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_01_experimental.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60434e34",
   "metadata": {},
   "source": [
    "xxxxxxxxxxxxxxxxxxxxxxxxxxTraining Loop xxxxxxxxxxxxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7970406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10  \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_01_experimental.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_01_experimental(inputs, targets)  # Forward pass\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.6f}\")\n",
    "    # Validation step\n",
    "    model_01_experimental.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, targets).item()\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Val Loss: {val_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27811f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
