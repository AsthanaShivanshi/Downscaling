{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59cbadfd",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!This script contains maskign code before standardisation. however standardisation of inputs and targets was performed before the interpol√©ated baselines were generated via CDO for bilinear and bicubic and then masked so that they only retain the Swiss Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f882966",
   "metadata": {},
   "source": [
    "Workflow : Bilinear interpolation, bicubic interpolation, Masking to retain only the swiss domain, splitting into train, test val, gridded RMSE R2, pooled RMSE, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0cc5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dependencies import *\n",
    "import sys\n",
    "sys.path.append(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/Scripts/Functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974f0555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:36733' processes=4 threads=4, memory=503.49 GiB>\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client= Client()\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16a4bb6",
   "metadata": {},
   "source": [
    "bilinear interpolation to the 1 km grid was performed using CDO remapbil with RhiresD/TabsD as reference files. Same for remapbic (Bicubic interpolation) Now they will be masked in this script so that it only retains the Swiss domain and not entire Europe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ec0120",
   "metadata": {},
   "source": [
    "#For precipitation mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cae0b59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask saved at /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/RhiresD_mask.nc\n"
     ]
    }
   ],
   "source": [
    "hr_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/raw/RhiresD_1971_2022.nc\"\n",
    "mask_output_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/RhiresD_mask.nc\"\n",
    "\n",
    "ds_hr = xr.open_dataset(hr_path)\n",
    "\n",
    "varname = \"RhiresD\" \n",
    "\n",
    "mask_rhiresd = xr.where(~np.isnan(ds_hr[varname].isel(time=0)), 1, 0)\n",
    "\n",
    "mask_rhiresd = mask_rhiresd.squeeze(drop=True)\n",
    "\n",
    "mask_rhiresd.to_netcdf(mask_output_path)\n",
    "\n",
    "print(f\"Mask saved at {mask_output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c46114",
   "metadata": {},
   "source": [
    "#For temperature mask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1101c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/raw/TabsD_1971_2022.nc\"\n",
    "mask_output_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/TabsD_mask.nc\"\n",
    "\n",
    "ds_hr = xr.open_dataset(hr_path)\n",
    "\n",
    "varname = \"TabsD\" \n",
    "\n",
    "mask_tabsd = xr.where(~np.isnan(ds_hr[varname].isel(time=0)), 1, 0)\n",
    "\n",
    "mask_tabsd = mask_tabsd.squeeze(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa82d86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask saved at /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/TabsD_mask.nc\n"
     ]
    }
   ],
   "source": [
    "mask_tabsd.to_netcdf(mask_output_path)\n",
    "\n",
    "print(f\"Mask saved at {mask_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bbad85",
   "metadata": {},
   "source": [
    "#Application of the mask to the two datasets : RhiresD and TabsD masks (1km) to the bicubically interpolated 1 km datasets features from Sven`s files so that it only retains the Swiss Domain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8b6128",
   "metadata": {},
   "source": [
    "Lazy loading was used below to allow for parallel computation. The data was not loading due to xarray loading everything at once and the kernel was crashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3c8af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "bicubic_ds_precip = xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processing/features_precip_bicubic.nc\",chunks={\"time\": 500})\n",
    "\n",
    "# Masking the features to retain the swiss domain\n",
    "masked_bicubic_rhiresd = bicubic_ds_precip * mask_rhiresd\n",
    "\n",
    "masked_bicubic_rhiresd.to_netcdf(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/features_precip_masked_bicubic.nc\",\n",
    "                                 engine=\"netcdf4\",\n",
    "                                    compute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f703d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "bicubic_ds_temp = xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processing/features_tas_bicubic.nc\",chunks={\"time\": 500})\n",
    "\n",
    "# Masking the features to retain the swiss domain\n",
    "masked_bicubic_temp = bicubic_ds_temp * mask_tabsd\n",
    "\n",
    "masked_bicubic_temp.to_netcdf(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/features_tas_masked_bicubic.nc\",\n",
    "                                 engine=\"netcdf4\",\n",
    "                                    compute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226f3458",
   "metadata": {},
   "source": [
    "For reducing computation time\n",
    "#Could have used h5netcdf for faster computation\n",
    "#Could have asked for more resources installed dask distributed, and used all 4 CPU cores, computing time reduced to 30 seconds!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a259b",
   "metadata": {},
   "source": [
    "Bilinear interpolated outputs : Maskign with the 1 km RhiresD and TabsD mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c47fc5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilinear_ds_precip = xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processing/features_precip_biliear.nc\",chunks={\"time\": 500})\n",
    "\n",
    "# Masking\n",
    "masked_bilinear_precip = bilinear_ds_precip * mask_rhiresd\n",
    "\n",
    "masked_bilinear_precip.to_netcdf(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bilinear/features_precip_masked_bilinear.nc\",\n",
    "                                 engine=\"netcdf4\",\n",
    "                                    compute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a5d7c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilinear_ds_temp = xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processing/features_tas_biliear.nc\",chunks={\"time\": 500})\n",
    "\n",
    "# Masking\n",
    "masked_bilinear_temp = bilinear_ds_temp * mask_tabsd\n",
    "\n",
    "masked_bilinear_temp.to_netcdf(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bilinear/features_tas_masked_bilinear.nc\",\n",
    "                                 engine=\"netcdf4\",\n",
    "                                    compute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1e2d8e",
   "metadata": {},
   "source": [
    "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxCHECKING SHAPExxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b6d6b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_ds_precip = xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/features_precip_masked_bicubic.nc\")[\"pr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1525a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ds_temp= xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/features_tas_masked_bicubic.nc\")[\"tas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28c68e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18993, 265, 370)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ds_precip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f086c302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18993, 265, 370)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ds_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83e99157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18993, 265, 370)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_precip= xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/raw/RhiresD_1971_2022.nc\")[\"RhiresD\"]\n",
    "targets_precip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51df3de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18993, 265, 370)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_temp= xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/raw/TabsD_1971_2022.nc\")[\"TabsD\"]\n",
    "targets_temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce5d13c",
   "metadata": {},
   "source": [
    "SHAPES MATCH!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cff50f",
   "metadata": {},
   "source": [
    "The entire dataset will be divided into tain, test val for both bilinear and bicubic interpolation for calculating standardisation metric etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2daae10",
   "metadata": {},
   "source": [
    "Split will be performed on one dataset, then replicated for the other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d960fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/ML_models\")\n",
    "\n",
    "from Train_Test_Val import split_by_decade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1714fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Combined/features_precip_masked_bicubic.nc\"\n",
    "tas_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Combined/features_tas_masked_bicubic.nc\"\n",
    "\n",
    "output_base = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic\"\n",
    "ds_precip = xr.open_dataset(precip_path, chunks={\"time\": 50})\n",
    "ds_tas = xr.open_dataset(tas_path, chunks={\"time\": 50})\n",
    "\n",
    "times = ds_precip['time'].values  # Assumes both datasets have matching time axis, one of the time coordinates from both datasets extracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4606125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx, test_idx = split_by_decade(times, seed=42)  # See has been fixed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33683b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c478c69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2751,  2462,  2313,  ..., 18657, 18129, 18958]),\n",
       " tensor([  486,  1772,  1052,  ..., 18762, 18652, 18403]),\n",
       " tensor([ 2936,   400,  3011,  ..., 18911, 18736, 18547]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, val_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e20a74ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13293])\n",
      "torch.Size([3796])\n",
      "torch.Size([1904])\n"
     ]
    }
   ],
   "source": [
    "print(train_idx.shape)\n",
    "print(val_idx.shape)\n",
    "print(test_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "394e13ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_splits(ds, indices, subset_folder, filename):\n",
    "    subset = ds.isel(time=indices)\n",
    "    subset = subset.chunk({\"time\": 50}) \n",
    "    save_dir = os.path.join(output_base, subset_folder)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    \n",
    "    delayed_obj = subset.to_netcdf(save_path, engine=\"netcdf4\", compute=True)\n",
    "    \n",
    "    print(f\"Saved {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dcf610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features_precip_masked_bicubic_train.nc\n",
      "Saved features_precip_masked_bicubic_val.nc\n",
      "Saved features_precip_masked_bicubic_test.nc\n"
     ]
    }
   ],
   "source": [
    "# Precipitation input dataset for bicubic interpolation split into three categories\n",
    "save_splits(ds_precip, train_idx, \"Train\", \"features_precip_masked_bicubic_train.nc\")\n",
    "save_splits(ds_precip, val_idx, \"Val\", \"features_precip_masked_bicubic_val.nc\")\n",
    "save_splits(ds_precip, test_idx, \"Test\", \"features_precip_masked_bicubic_test.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b88a939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features_tas_masked_bicubic_train.nc\n",
      "Saved features_tas_masked_bicubic_val.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 17:01:43,767 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40737\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:53328 remote=tcp://127.0.0.1:40737>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2025-05-01 17:01:43,768 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40737\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 228, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 367, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 137, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:53312 remote=tcp://127.0.0.1:40737>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features_tas_masked_bicubic_test.nc\n"
     ]
    }
   ],
   "source": [
    "# Temperature input dataset for bicubic interpolation split into three categories\n",
    "save_splits(ds_tas, train_idx, \"Train\", \"features_tas_masked_bicubic_train.nc\")\n",
    "save_splits(ds_tas, val_idx, \"Val\", \"features_tas_masked_bicubic_val.nc\")\n",
    "save_splits(ds_tas, test_idx, \"Test\", \"features_tas_masked_bicubic_test.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168f33e5",
   "metadata": {},
   "source": [
    "Also splittign the targets along the very same lines usign the reproducible split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e98a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_target = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/raw/RhiresD_1971_2022.nc\"\n",
    "tas_target = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/raw/TabsD_1971_2022.nc\"\n",
    "\n",
    "output_base = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic\"\n",
    "ds_precip = xr.open_dataset(precip_target, chunks={\"time\": 50})\n",
    "ds_tas = xr.open_dataset(tas_target, chunks={\"time\": 50})\n",
    "\n",
    "times = ds_precip['time'].values  # Assumes both datasets have matching time axis, one of the time coordinates from both datasets extracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4eb0bd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved targets_precip_masked_train.nc\n",
      "Saved targets_precip_masked_val.nc\n",
      "Saved targets_precip_masked_test.nc\n"
     ]
    }
   ],
   "source": [
    "# Precipitation input dataset for bicubic interpolation split into three categories\n",
    "save_splits(ds_precip, train_idx, \"Train\", \"targets_precip_masked_train.nc\")\n",
    "save_splits(ds_precip, val_idx, \"Val\", \"targets_precip_masked_val.nc\")\n",
    "save_splits(ds_precip, test_idx, \"Test\", \"targets_precip_masked_test.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4740b5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved targets_tas_masked_train.nc\n",
      "Saved targets_tas_masked_val.nc\n",
      "Saved targets_tas_masked_test.nc\n"
     ]
    }
   ],
   "source": [
    "# Precipitation input dataset for bicubic interpolation split into three categories\n",
    "save_splits(ds_tas, train_idx, \"Train\", \"targets_tas_masked_train.nc\")\n",
    "save_splits(ds_tas, val_idx, \"Val\", \"targets_tas_masked_val.nc\")\n",
    "save_splits(ds_tas, test_idx, \"Test\", \"targets_tas_masked_test.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdeed40",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e6c5dfe",
   "metadata": {},
   "source": [
    "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxDoing the same train test val split for bilinear nterpolation xxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15015063",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_path_bilinear = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Combined/features_precip_masked_bilinear.nc\"\n",
    "tas_path_bilinear = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Combined/features_tas_masked_bilinear.nc\"\n",
    "\n",
    "output_base = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bilinear\"\n",
    "ds_precip_bilinear = xr.open_dataset(precip_path_bilinear, chunks={\"time\": 50})\n",
    "ds_tas_bilinear = xr.open_dataset(tas_path_bilinear, chunks={\"time\": 50})\n",
    "\n",
    "times = ds_precip_bilinear['time'].values  # Assumes both datasets have matching time axis, one of the time coordinates from both datasets extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8fbc6c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 17:16:50,663 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:38899 -> tcp://127.0.0.1:46187\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 1795, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:38899 remote=tcp://127.0.0.1:43136>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2025-05-01 17:16:50,663 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46187\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:46814 remote=tcp://127.0.0.1:46187>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2025-05-01 17:16:50,665 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46187\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 231, in read\n",
      "    buffer = await read_bytes_rw(stream, buffer_nbytes)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 367, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 137, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:45644 remote=tcp://127.0.0.1:46187>: Stream is closed\n",
      "2025-05-01 17:16:50,667 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46187\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 228, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 367, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 137, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:46800 remote=tcp://127.0.0.1:46187>: Stream is closed\n",
      "2025-05-01 17:17:27,770 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:33387\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:47856 remote=tcp://127.0.0.1:33387>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2025-05-01 17:17:27,770 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:33387\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:58534 remote=tcp://127.0.0.1:33387>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2025-05-01 17:17:27,771 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:33387\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:47866 remote=tcp://127.0.0.1:33387>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2025-05-01 17:17:27,771 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:38899 -> tcp://127.0.0.1:33387\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 1795, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:38899 remote=tcp://127.0.0.1:55206>: ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features_precip_masked_bilinear_train.nc\n",
      "Saved features_precip_masked_bilinear_val.nc\n",
      "Saved features_precip_masked_bilinear_test.nc\n"
     ]
    }
   ],
   "source": [
    "# Precipitation input dataset for bicubic interpolation split into three categories\n",
    "save_splits(ds_precip_bilinear, train_idx, \"Train\", \"features_precip_masked_bilinear_train.nc\")\n",
    "save_splits(ds_precip_bilinear, val_idx, \"Val\", \"features_precip_masked_bilinear_val.nc\")\n",
    "save_splits(ds_precip_bilinear, test_idx, \"Test\", \"features_precip_masked_bilinear_test.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35286467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features_tas_masked_bilinear_train.nc\n",
      "Saved features_tas_masked_bilinear_val.nc\n",
      "Saved features_tas_masked_bilinear_test.nc\n"
     ]
    }
   ],
   "source": [
    "# Precipitation input dataset for bicubic interpolation split into three categories\n",
    "save_splits(ds_tas_bilinear, train_idx, \"Train\", \"features_tas_masked_bilinear_train.nc\")\n",
    "save_splits(ds_tas_bilinear, val_idx, \"Val\", \"features_tas_masked_bilinear_val.nc\")\n",
    "save_splits(ds_tas_bilinear, test_idx, \"Test\", \"features_tas_masked_bilinear_test.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ef2b37",
   "metadata": {},
   "source": [
    "                                                  xxxxxxxxxxStandardisation code  xxxxxxxxxxxxxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf3811d",
   "metadata": {},
   "source": [
    "Standardisation has to be performed avoiding data leakage. Hence, the train -test contamination has to be avoided. \n",
    "\n",
    "Can be done using statistics only for the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517db7f7",
   "metadata": {},
   "source": [
    "The mean, std, min, max and range of the training set will then be used to perform scaling for the test set as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304fd538",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05e76000",
   "metadata": {},
   "source": [
    "xxxxxxxxxxxxPerforming standardisation for the training set for both precip and temperaturexxxxx. Training will be performed on the bicubically interpolated dataset for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a128293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Standardise import standardise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031b2e05",
   "metadata": {},
   "source": [
    "Temperature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba11b753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1f70601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised/min max scaled variable saved to /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/SCALED_features_tas_masked_bicubic_train.nc\n"
     ]
    }
   ],
   "source": [
    "input_path = '/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/features_tas_masked_bicubic_train.nc'\n",
    "output_path = '/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/SCALED_features_tas_masked_bicubic_train.nc'\n",
    "var = 'tas'\n",
    "\n",
    "standardise(input_path, output_path, var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1799b82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets of the training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1be1ee96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/sasthana/.local/lib/python3.12/site-packages/dask/array/numpy_compat.py:57: RuntimeWarning: invalid value encountered in divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised/min max scaled variable saved to /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/SCALED_targets_tas_masked_train.nc\n"
     ]
    }
   ],
   "source": [
    "input_path = '/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/targets_tas_masked_train.nc'\n",
    "output_path = '/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/SCALED_targets_tas_masked_train.nc'\n",
    "var = 'TabsD'\n",
    "\n",
    "standardise(input_path, output_path, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84a8524",
   "metadata": {},
   "source": [
    "PRECIPITATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e210e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a813b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/sasthana/.local/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/users/sasthana/.local/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/users/sasthana/.local/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/users/sasthana/.local/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised/min max scaled variable saved to /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/SCALED_features_precip_masked_bicubic_train.nc\n"
     ]
    }
   ],
   "source": [
    "input_path = '/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/features_precip_masked_bicubic_train.nc'\n",
    "output_path = '/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/SCALED_features_precip_masked_bicubic_train.nc'\n",
    "var = 'pr'\n",
    "\n",
    "standardise(input_path, output_path, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e70b4db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised/min max scaled variable saved to /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/SCALED_targets_precip_masked_train.nc\n"
     ]
    }
   ],
   "source": [
    "input_path = '/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/targets_precip_masked_train.nc'\n",
    "output_path = '/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/SCALED_targets_precip_masked_train.nc'\n",
    "var = 'RhiresD'\n",
    "\n",
    "standardise(input_path, output_path, var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
