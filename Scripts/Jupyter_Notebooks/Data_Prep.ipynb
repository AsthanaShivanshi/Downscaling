{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59cbadfd",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!This script contains maskign code before standardisation. however standardisation of inputs and targets was performed before the interpol√©ated baselines were generated via CDO for bilinear and bicubic and then masked so that they only retain the Swiss Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f882966",
   "metadata": {},
   "source": [
    "Workflow : Bilinear interpolation, bicubic interpolation, Masking to retain only the swiss domain, splitting into train, test val, gridded RMSE R2, pooled RMSE, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0cc5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/Scripts/Functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49e07b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "974f0555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:41009' processes=4 threads=4, memory=503.49 GiB>\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client= Client()\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16a4bb6",
   "metadata": {},
   "source": [
    "bilinear interpolation to the 1 km grid was performed using CDO remapbil with RhiresD/TabsD as reference files. Same for remapbic (Bicubic interpolation) Now they will be masked in this script so that it only retains the Swiss domain and not entire Europe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ec0120",
   "metadata": {},
   "source": [
    "#For precipitation mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226f3458",
   "metadata": {},
   "source": [
    "For reducing computation time\n",
    "#Could have used h5netcdf for faster computation\n",
    "#Could have asked for more resources installed dask distributed, and used all 4 CPU cores, computing time reduced to 30 seconds!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a259b",
   "metadata": {},
   "source": [
    "Bilinear interpolated outputs : Maskign with the 1 km RhiresD and TabsD mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1e2d8e",
   "metadata": {},
   "source": [
    "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxCHECKING SHAPExxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b6d6b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_ds_precip = xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/features_precip_masked_bicubic.nc\")[\"pr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1525a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ds_temp= xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/features_tas_masked_bicubic.nc\")[\"tas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c68e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18993, 265, 370)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ds_precip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f086c302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18993, 265, 370)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ds_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83e99157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18993, 265, 370)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_precip= xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/raw/RhiresD_1971_2022.nc\")[\"RhiresD\"]\n",
    "targets_precip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51df3de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18993, 265, 370)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_temp= xr.open_dataset(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/raw/TabsD_1971_2022.nc\")[\"TabsD\"]\n",
    "targets_temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce5d13c",
   "metadata": {},
   "source": [
    "SHAPES MATCH!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cff50f",
   "metadata": {},
   "source": [
    "The entire dataset will be divided into tain, test val for both bilinear and bicubic interpolation for calculating standardisation metric etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2daae10",
   "metadata": {},
   "source": [
    "Split will be performed on one dataset, then replicated for the other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7d960fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/ML_models\")\n",
    "\n",
    "from Train_Test_Val import split_by_decade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1714fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Combined/features_precip_masked_bicubic.nc\"\n",
    "tas_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Combined/features_tas_masked_bicubic.nc\"\n",
    "\n",
    "output_base = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic\"\n",
    "ds_precip = xr.open_dataset(precip_path, chunks={\"time\": 50})\n",
    "ds_tas = xr.open_dataset(tas_path, chunks={\"time\": 50})\n",
    "\n",
    "times = ds_precip['time'].values  # Assumes both datasets have matching time axis, one of the time coordinates from both datasets extracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4606125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx, test_idx = split_by_decade(times, seed=42)  # See has been fixed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33683b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c478c69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2751,  2462,  2313,  ..., 18657, 18129, 18958]),\n",
       " tensor([  486,  1772,  1052,  ..., 18762, 18652, 18403]),\n",
       " tensor([ 2936,   400,  3011,  ..., 18911, 18736, 18547]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, val_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e20a74ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13293])\n",
      "torch.Size([3796])\n",
      "torch.Size([1904])\n"
     ]
    }
   ],
   "source": [
    "print(train_idx.shape)\n",
    "print(val_idx.shape)\n",
    "print(test_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "394e13ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_splits(ds, indices, subset_folder, filename):\n",
    "    subset = ds.isel(time=indices)\n",
    "    subset = subset.chunk({\"time\": 50}) \n",
    "    save_dir = os.path.join(output_base, subset_folder)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    \n",
    "    delayed_obj = subset.to_netcdf(save_path, engine=\"netcdf4\", compute=True)\n",
    "    \n",
    "    print(f\"Saved {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dcf610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features_precip_masked_bicubic_train.nc\n",
      "Saved features_precip_masked_bicubic_val.nc\n",
      "Saved features_precip_masked_bicubic_test.nc\n"
     ]
    }
   ],
   "source": [
    "# Precipitation input dataset for bicubic interpolation split into three categories\n",
    "save_splits(ds_precip, train_idx, \"Train\", \"features_precip_masked_bicubic_train.nc\")\n",
    "save_splits(ds_precip, val_idx, \"Val\", \"features_precip_masked_bicubic_val.nc\")\n",
    "save_splits(ds_precip, test_idx, \"Test\", \"features_precip_masked_bicubic_test.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b88a939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 11:49:01,789 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:35323 -> tcp://127.0.0.1:41593\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/worker.py\", line 1795, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:35323 remote=tcp://127.0.0.1:40686>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2025-05-09 11:49:01,790 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:34087 -> tcp://127.0.0.1:41593\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/worker.py\", line 1795, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:34087 remote=tcp://127.0.0.1:36450>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2025-05-09 11:49:01,791 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:41593\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:41418 remote=tcp://127.0.0.1:41593>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2025-05-09 11:49:01,793 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:41593\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:41414 remote=tcp://127.0.0.1:41593>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2025-05-09 11:49:07,444 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:35323\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 228, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 367, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 137, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:49890 remote=tcp://127.0.0.1:35323>: Stream is closed\n",
      "2025-05-09 11:49:07,444 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:35323\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:40670 remote=tcp://127.0.0.1:35323>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2025-05-09 11:49:07,444 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:35323\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:59210 remote=tcp://127.0.0.1:35323>: ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features_tas_masked_bicubic_train.nc\n",
      "Saved features_tas_masked_bicubic_val.nc\n",
      "Saved features_tas_masked_bicubic_test.nc\n"
     ]
    }
   ],
   "source": [
    "# Temperature input dataset for bicubic interpolation split into three categories\n",
    "save_splits(ds_tas, train_idx, \"Train\", \"features_tas_masked_bicubic_train.nc\")\n",
    "save_splits(ds_tas, val_idx, \"Val\", \"features_tas_masked_bicubic_val.nc\")\n",
    "save_splits(ds_tas, test_idx, \"Test\", \"features_tas_masked_bicubic_test.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168f33e5",
   "metadata": {},
   "source": [
    "Also splittign the targets along the very same lines usign the reproducible split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e98a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_target = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/raw/RhiresD_1971_2022.nc\"\n",
    "tas_target = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/raw/TabsD_1971_2022.nc\"\n",
    "\n",
    "output_base = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic\"\n",
    "ds_precip = xr.open_dataset(precip_target, chunks={\"time\": 50})\n",
    "ds_tas = xr.open_dataset(tas_target, chunks={\"time\": 50})\n",
    "\n",
    "times = ds_precip['time'].values  # Assumes both datasets have matching time axis, one of the time coordinates from both datasets extracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4eb0bd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved targets_precip_masked_train.nc\n",
      "Saved targets_precip_masked_val.nc\n",
      "Saved targets_precip_masked_test.nc\n"
     ]
    }
   ],
   "source": [
    "# Precipitation input dataset for bicubic interpolation split into three categories\n",
    "save_splits(ds_precip, train_idx, \"Train\", \"targets_precip_masked_train.nc\")\n",
    "save_splits(ds_precip, val_idx, \"Val\", \"targets_precip_masked_val.nc\")\n",
    "save_splits(ds_precip, test_idx, \"Test\", \"targets_precip_masked_test.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4740b5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved targets_tas_masked_train.nc\n",
      "Saved targets_tas_masked_val.nc\n",
      "Saved targets_tas_masked_test.nc\n"
     ]
    }
   ],
   "source": [
    "# Precipitation input dataset for bicubic interpolation split into three categories\n",
    "save_splits(ds_tas, train_idx, \"Train\", \"targets_tas_masked_train.nc\")\n",
    "save_splits(ds_tas, val_idx, \"Val\", \"targets_tas_masked_val.nc\")\n",
    "save_splits(ds_tas, test_idx, \"Test\", \"targets_tas_masked_test.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdeed40",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e6c5dfe",
   "metadata": {},
   "source": [
    "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxDoing the same train test val split for bilinear nterpolation xxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15015063",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_path_bilinear = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Combined/features_precip_masked_bilinear.nc\"\n",
    "tas_path_bilinear = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Combined/features_tas_masked_bilinear.nc\"\n",
    "\n",
    "output_base = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bilinear\"\n",
    "ds_precip_bilinear = xr.open_dataset(precip_path_bilinear, chunks={\"time\": 50})\n",
    "ds_tas_bilinear = xr.open_dataset(tas_path_bilinear, chunks={\"time\": 50})\n",
    "\n",
    "times = ds_precip_bilinear['time'].values  # Assumes both datasets have matching time axis, one of the time coordinates from both datasets extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8fbc6c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 17:16:50,663 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:38899 -> tcp://127.0.0.1:46187\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 1795, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:38899 remote=tcp://127.0.0.1:43136>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2025-05-01 17:16:50,663 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46187\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:46814 remote=tcp://127.0.0.1:46187>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2025-05-01 17:16:50,665 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46187\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 231, in read\n",
      "    buffer = await read_bytes_rw(stream, buffer_nbytes)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 367, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 137, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:45644 remote=tcp://127.0.0.1:46187>: Stream is closed\n",
      "2025-05-01 17:16:50,667 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46187\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 228, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 367, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 137, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:46800 remote=tcp://127.0.0.1:46187>: Stream is closed\n",
      "2025-05-01 17:17:27,770 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:33387\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:47856 remote=tcp://127.0.0.1:33387>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2025-05-01 17:17:27,770 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:33387\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:58534 remote=tcp://127.0.0.1:33387>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2025-05-01 17:17:27,771 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:33387\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2073, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 2879, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:47866 remote=tcp://127.0.0.1:33387>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2025-05-01 17:17:27,771 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:38899 -> tcp://127.0.0.1:33387\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/worker.py\", line 1795, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/users/sasthana/.local/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:38899 remote=tcp://127.0.0.1:55206>: ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features_precip_masked_bilinear_train.nc\n",
      "Saved features_precip_masked_bilinear_val.nc\n",
      "Saved features_precip_masked_bilinear_test.nc\n"
     ]
    }
   ],
   "source": [
    "# Precipitation input dataset for bicubic interpolation split into three categories\n",
    "save_splits(ds_precip_bilinear, train_idx, \"Train\", \"features_precip_masked_bilinear_train.nc\")\n",
    "save_splits(ds_precip_bilinear, val_idx, \"Val\", \"features_precip_masked_bilinear_val.nc\")\n",
    "save_splits(ds_precip_bilinear, test_idx, \"Test\", \"features_precip_masked_bilinear_test.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35286467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features_tas_masked_bilinear_train.nc\n",
      "Saved features_tas_masked_bilinear_val.nc\n",
      "Saved features_tas_masked_bilinear_test.nc\n"
     ]
    }
   ],
   "source": [
    "# Precipitation input dataset for bicubic interpolation split into three categories\n",
    "save_splits(ds_tas_bilinear, train_idx, \"Train\", \"features_tas_masked_bilinear_train.nc\")\n",
    "save_splits(ds_tas_bilinear, val_idx, \"Val\", \"features_tas_masked_bilinear_val.nc\")\n",
    "save_splits(ds_tas_bilinear, test_idx, \"Test\", \"features_tas_masked_bilinear_test.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ef2b37",
   "metadata": {},
   "source": [
    "                                                  xxxxxxxxxxStandardisation code  xxxxxxxxxxxxxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf3811d",
   "metadata": {},
   "source": [
    "Standardisation has to be performed avoiding data leakage. Hence, the train -test contamination has to be avoided. \n",
    "\n",
    "Can be done using statistics only for the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517db7f7",
   "metadata": {},
   "source": [
    "The mean, std, min, max and range of the training set will then be used to perform scaling for the test set as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e76000",
   "metadata": {},
   "source": [
    "xxxxxxxxxxxxPerforming standardisation for the training set for both precip and temperaturexxxxx. Training will be performed on the bicubically interpolated dataset for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a128293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Standardise import standardise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031b2e05",
   "metadata": {},
   "source": [
    "Temperature "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fef20ed",
   "metadata": {},
   "source": [
    "Loading inputs and targets once again separately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b56c10",
   "metadata": {},
   "source": [
    "#Scaling Precipitation training features and targets (from bicubic interpolation features): targets and features get scaled by their own mean and std. The same parametersa then used to standardise testing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1551486b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised/scaled variable saved to /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/SCALED_features_precip_masked_bicubic_train.nc\n"
     ]
    }
   ],
   "source": [
    "input_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/features_precip_masked_bicubic_train.nc\"\n",
    "output_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/SCALED_features_precip_masked_bicubic_train.nc\"\n",
    "var = \"pr\"\n",
    "precip_min, precip_max = standardise(input_path, output_path, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ea0b3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised/scaled variable saved to /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/SCALED_targets_precip_masked_train.nc\n"
     ]
    }
   ],
   "source": [
    "input_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/targets_precip_masked_train.nc\"\n",
    "output_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/SCALED_targets_precip_masked_train.nc\"\n",
    "var = \"RhiresD\"\n",
    "target_min, target_max = standardise(input_path, output_path, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502bccff",
   "metadata": {},
   "source": [
    "Using above mean, max, std and min from temp and precip to standardise the vcalidation and testing data to avoid data leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb527d30",
   "metadata": {},
   "source": [
    "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxPRECIPITATIONxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "980425b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised/scaled variable saved to /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Val/SCALED_features_precip_masked_bicubic_val.nc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<xarray.DataArray 'pr' (N: 265, E: 370)> Size: 784kB\n",
       " dask.array<_nanmin_skip-aggregate, shape=(265, 370), dtype=float64, chunksize=(265, 370), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     lon      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "     lat      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "   * E        (E) float64 3kB 2.474e+06 2.476e+06 ... 2.842e+06 2.844e+06\n",
       "   * N        (N) float64 2kB 1.06e+06 1.06e+06 1.062e+06 ... 1.322e+06 1.324e+06,\n",
       " <xarray.DataArray 'pr' (N: 265, E: 370)> Size: 784kB\n",
       " dask.array<_nanmax_skip-aggregate, shape=(265, 370), dtype=float64, chunksize=(265, 370), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     lon      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "     lat      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "   * E        (E) float64 3kB 2.474e+06 2.476e+06 ... 2.842e+06 2.844e+06\n",
       "   * N        (N) float64 2kB 1.06e+06 1.06e+06 1.062e+06 ... 1.322e+06 1.324e+06)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation features :Precip\n",
    "input_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Val/features_precip_masked_bicubic_val.nc\"\n",
    "output_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Val/SCALED_features_precip_masked_bicubic_val.nc\"\n",
    "var = \"pr\"\n",
    "standardise(input_path, output_path, var, min=precip_min, max=precip_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cd54c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised/scaled variable saved to /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Val/SCALED_targets_precip_masked_val.nc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<xarray.DataArray 'RhiresD' (N: 265, E: 370)> Size: 392kB\n",
       " dask.array<_nanmin_skip-aggregate, shape=(265, 370), dtype=float32, chunksize=(265, 370), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     lon      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "     lat      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "   * E        (E) float64 3kB 2.474e+06 2.476e+06 ... 2.842e+06 2.844e+06\n",
       "   * N        (N) float64 2kB 1.06e+06 1.06e+06 1.062e+06 ... 1.322e+06 1.324e+06,\n",
       " <xarray.DataArray 'RhiresD' (N: 265, E: 370)> Size: 392kB\n",
       " dask.array<_nanmax_skip-aggregate, shape=(265, 370), dtype=float32, chunksize=(265, 370), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     lon      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "     lat      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "   * E        (E) float64 3kB 2.474e+06 2.476e+06 ... 2.842e+06 2.844e+06\n",
       "   * N        (N) float64 2kB 1.06e+06 1.06e+06 1.062e+06 ... 1.322e+06 1.324e+06)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Validation targets:  Precip\n",
    "input_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Val/targets_precip_masked_val.nc\"\n",
    "output_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Val/SCALED_targets_precip_masked_val.nc\"\n",
    "var = \"RhiresD\"\n",
    "standardise(input_path, output_path, var, min=target_min, max=target_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f552a2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised/scaled variable saved to /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Test/SCALED_features_precip_masked_bicubic_test.nc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<xarray.DataArray 'pr' (N: 265, E: 370)> Size: 784kB\n",
       " dask.array<_nanmin_skip-aggregate, shape=(265, 370), dtype=float64, chunksize=(265, 370), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     lon      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "     lat      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "   * E        (E) float64 3kB 2.474e+06 2.476e+06 ... 2.842e+06 2.844e+06\n",
       "   * N        (N) float64 2kB 1.06e+06 1.06e+06 1.062e+06 ... 1.322e+06 1.324e+06,\n",
       " <xarray.DataArray 'pr' (N: 265, E: 370)> Size: 784kB\n",
       " dask.array<_nanmax_skip-aggregate, shape=(265, 370), dtype=float64, chunksize=(265, 370), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     lon      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "     lat      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "   * E        (E) float64 3kB 2.474e+06 2.476e+06 ... 2.842e+06 2.844e+06\n",
       "   * N        (N) float64 2kB 1.06e+06 1.06e+06 1.062e+06 ... 1.322e+06 1.324e+06)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precipitation test features\n",
    "input_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Test/features_precip_masked_bicubic_test.nc\"\n",
    "output_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Test/SCALED_features_precip_masked_bicubic_test.nc\"\n",
    "var = \"pr\"\n",
    "standardise(input_path, output_path, var, min=precip_min, max=precip_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "799a0855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised/scaled variable saved to /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Test/SCALED_targets_precip_masked_test.nc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<xarray.DataArray 'RhiresD' (N: 265, E: 370)> Size: 392kB\n",
       " dask.array<_nanmin_skip-aggregate, shape=(265, 370), dtype=float32, chunksize=(265, 370), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     lon      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "     lat      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "   * E        (E) float64 3kB 2.474e+06 2.476e+06 ... 2.842e+06 2.844e+06\n",
       "   * N        (N) float64 2kB 1.06e+06 1.06e+06 1.062e+06 ... 1.322e+06 1.324e+06,\n",
       " <xarray.DataArray 'RhiresD' (N: 265, E: 370)> Size: 392kB\n",
       " dask.array<_nanmax_skip-aggregate, shape=(265, 370), dtype=float32, chunksize=(265, 370), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     lon      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "     lat      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "   * E        (E) float64 3kB 2.474e+06 2.476e+06 ... 2.842e+06 2.844e+06\n",
       "   * N        (N) float64 2kB 1.06e+06 1.06e+06 1.062e+06 ... 1.322e+06 1.324e+06)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precipitation test targets\n",
    "input_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Test/targets_precip_masked_test.nc\"\n",
    "output_path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Test/SCALED_targets_precip_masked_test.nc\"\n",
    "var = \"RhiresD\"\n",
    "standardise(input_path, output_path, var, min=target_min, max=target_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d3dd4",
   "metadata": {},
   "source": [
    "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxTEMPERATURE : Val and test targets and features standardisationxxxxxxxxxxxxxxxx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad21c6",
   "metadata": {},
   "source": [
    "Training features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20838af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/_task_spec.py:758: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised/scaled variable saved to /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/SCALED_features_tas_masked_bicubic_train.nc\n"
     ]
    }
   ],
   "source": [
    "tas_mean, tas_std = standardise(\n",
    "    input_path=\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/features_tas_masked_bicubic_train.nc\",\n",
    "    output_path=\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/SCALED_features_tas_masked_bicubic_train.nc\",\n",
    "    var=\"tas\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fce326",
   "metadata": {},
   "source": [
    "Training targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7172f65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/array/numpy_compat.py:57: RuntimeWarning: invalid value encountered in divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised/scaled variable saved to /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/SCALED_targets_tas_masked_train.nc\n"
     ]
    }
   ],
   "source": [
    "tabsd_mean, tabsd_std = standardise(\n",
    "    input_path=\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/targets_tas_masked_train.nc\",\n",
    "    output_path=\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Train/SCALED_targets_tas_masked_train.nc\",\n",
    "    var=\"TabsD\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa02a8d",
   "metadata": {},
   "source": [
    "Now we have the parameters from the training set for temperature, the same will be used to scale the featurea and targets of the Val and Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fa7b63",
   "metadata": {},
   "source": [
    "Validation standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff408e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised/scaled variable saved to /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Val/SCALED_features_tas_masked_bicubic_val.nc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<xarray.DataArray 'tas' (N: 265, E: 370)> Size: 784kB\n",
       " dask.array<mean_agg-aggregate, shape=(265, 370), dtype=float64, chunksize=(265, 370), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     lon      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "     lat      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "   * E        (E) float64 3kB 2.474e+06 2.476e+06 ... 2.842e+06 2.844e+06\n",
       "   * N        (N) float64 2kB 1.06e+06 1.06e+06 1.062e+06 ... 1.322e+06 1.324e+06,\n",
       " <xarray.DataArray 'tas' (N: 265, E: 370)> Size: 784kB\n",
       " dask.array<_sqrt, shape=(265, 370), dtype=float64, chunksize=(265, 370), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     lon      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "     lat      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "   * E        (E) float64 3kB 2.474e+06 2.476e+06 ... 2.842e+06 2.844e+06\n",
       "   * N        (N) float64 2kB 1.06e+06 1.06e+06 1.062e+06 ... 1.322e+06 1.324e+06)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardise(\n",
    "    input_path=\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Val/features_tas_masked_bicubic_val.nc\",\n",
    "    output_path=\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Val/SCALED_features_tas_masked_bicubic_val.nc\",\n",
    "    var=\"tas\",\n",
    "    mean=tas_mean,\n",
    "    std=tas_std\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fcc6b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/MyPythonEnvironment/lib/python3.12/site-packages/dask/array/numpy_compat.py:57: RuntimeWarning: invalid value encountered in divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised/scaled variable saved to /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Val/SCALED_targets_tas_masked_val.nc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<xarray.DataArray 'TabsD' (N: 265, E: 370)> Size: 392kB\n",
       " dask.array<mean_agg-aggregate, shape=(265, 370), dtype=float32, chunksize=(265, 370), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     lon      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "     lat      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "   * E        (E) float64 3kB 2.474e+06 2.476e+06 ... 2.842e+06 2.844e+06\n",
       "   * N        (N) float64 2kB 1.06e+06 1.06e+06 1.062e+06 ... 1.322e+06 1.324e+06,\n",
       " <xarray.DataArray 'TabsD' (N: 265, E: 370)> Size: 392kB\n",
       " dask.array<_sqrt, shape=(265, 370), dtype=float32, chunksize=(265, 370), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     lon      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "     lat      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "   * E        (E) float64 3kB 2.474e+06 2.476e+06 ... 2.842e+06 2.844e+06\n",
       "   * N        (N) float64 2kB 1.06e+06 1.06e+06 1.062e+06 ... 1.322e+06 1.324e+06)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardise(\n",
    "    input_path=\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Val/targets_tas_masked_val.nc\",\n",
    "    output_path=\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Val/SCALED_targets_tas_masked_val.nc\",\n",
    "    var=\"TabsD\",\n",
    "    mean=tabsd_mean,\n",
    "    std=tabsd_std\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e02b86",
   "metadata": {},
   "source": [
    "Testing datasets for temepratures : standardisation of features and targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea24cb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised/scaled variable saved to /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Test/SCALED_features_tas_masked_bicubic_test.nc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<xarray.DataArray 'tas' (N: 265, E: 370)> Size: 784kB\n",
       " dask.array<mean_agg-aggregate, shape=(265, 370), dtype=float64, chunksize=(265, 370), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     lon      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "     lat      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "   * E        (E) float64 3kB 2.474e+06 2.476e+06 ... 2.842e+06 2.844e+06\n",
       "   * N        (N) float64 2kB 1.06e+06 1.06e+06 1.062e+06 ... 1.322e+06 1.324e+06,\n",
       " <xarray.DataArray 'tas' (N: 265, E: 370)> Size: 784kB\n",
       " dask.array<_sqrt, shape=(265, 370), dtype=float64, chunksize=(265, 370), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     lon      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "     lat      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "   * E        (E) float64 3kB 2.474e+06 2.476e+06 ... 2.842e+06 2.844e+06\n",
       "   * N        (N) float64 2kB 1.06e+06 1.06e+06 1.062e+06 ... 1.322e+06 1.324e+06)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardise(\n",
    "    input_path=\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Test/features_tas_masked_bicubic_test.nc\",\n",
    "    output_path=\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Test/SCALED_features_tas_masked_bicubic_test.nc\",\n",
    "    var=\"tas\",\n",
    "    mean=tas_mean,\n",
    "    std=tas_std\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a77f36aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised/scaled variable saved to /work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Test/SCALED_targets_tas_masked_test.nc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<xarray.DataArray 'TabsD' (N: 265, E: 370)> Size: 392kB\n",
       " dask.array<mean_agg-aggregate, shape=(265, 370), dtype=float32, chunksize=(265, 370), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     lon      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "     lat      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "   * E        (E) float64 3kB 2.474e+06 2.476e+06 ... 2.842e+06 2.844e+06\n",
       "   * N        (N) float64 2kB 1.06e+06 1.06e+06 1.062e+06 ... 1.322e+06 1.324e+06,\n",
       " <xarray.DataArray 'TabsD' (N: 265, E: 370)> Size: 392kB\n",
       " dask.array<_sqrt, shape=(265, 370), dtype=float32, chunksize=(265, 370), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     lon      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "     lat      (N, E) float32 392kB dask.array<chunksize=(265, 370), meta=np.ndarray>\n",
       "   * E        (E) float64 3kB 2.474e+06 2.476e+06 ... 2.842e+06 2.844e+06\n",
       "   * N        (N) float64 2kB 1.06e+06 1.06e+06 1.062e+06 ... 1.322e+06 1.324e+06)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardise(\n",
    "    input_path=\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Test/targets_tas_masked_test.nc\",\n",
    "    output_path=\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/sasthana/Downscaling/Downscaling/data/processed/Bicubic/Test/SCALED_targets_tas_masked_test.nc\",\n",
    "    var=\"TabsD\",\n",
    "    mean=tabsd_mean,\n",
    "    std=tabsd_std\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
