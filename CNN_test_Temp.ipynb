{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader,TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device= torch.device ('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code follows the architecture laid down in Ba√±o-Medina et al.,2020 for CNN10 architecture for temperature downscaling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function:  standardising the input temperature data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise_temperature_data(X):\n",
    "\n",
    "    scaler= StandardScaler() #Ensures all input variables have the same scale\n",
    "    X_scaled= scaler.fit_transform(X.reshape(-1, X.shape[-1]).reshape(X.shape))\n",
    "    return X_scaled, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Temperature Downscaling CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TempDownscalingCNN(nn.Module):\n",
    "    '''Defines a Pytorch neural network model for temperature downscaling based on number of input predictors variables (5 in this case on four different pressure levels)\n",
    "    and the output size (1 in this case, corr to one daily temperature value at each grid point)'''\n",
    "    def __init__(self,input_channels,output_size):\n",
    "        super(TempDownscalingCNN,self).__init__()\n",
    "\n",
    "        #The convolutional layers : There are three in this architecture following CNN10\n",
    "        self.conv1= nn.Conv2d(input_channels, 50, kernel_size=3) #50 is the number of kernels, 3x3x20 (20 =5 variables, 4 pressure levels)\n",
    "        self.conv2= nn.Conv2d(50,25,kernel_size=3) #Dimensions of the kernel are 3x3x50, based on the output from the last layer\n",
    "        self.conv3= nn.Conv2d(25,10,kernel_size=3) #3x3x25, as the previous layer had 25 kernels\n",
    "\n",
    "        #So the last convo layer above has 10 kernels of size 3x3. The output from this layer is then flattened and fed into the fully connected layers\n",
    "        #The fully connected layers \n",
    "        self.flatten= nn.Flatten() #The output from the last convo layer is flattened to be fed into the dense layer. Fully connected dense layers in \n",
    "        #Pytorch are implemented as Linear Layers (expect a 1 D input)\n",
    "    \n",
    "        #Now the dense layers. \n",
    "        \n",
    "        self.fc1= nn.Linear(10 *(output_size-6)* (output_size-6) ,output_size)\n",
    "\n",
    "        self.fc2 = nn.Linear(10 * (output_size-6) * (output_size-6), output_size)\n",
    "\n",
    "    #Now, defining the forward pass\n",
    "\n",
    "    def forward(self,x):\n",
    "        '''Defining the forward pass of the Temperature Downscaling Model'''\n",
    "        x=F.relu(self.conv1(x)) #Applying first convolution and activation\n",
    "        x=F.relu(self.conv2(x)) #Applying second convolution and activation\n",
    "        x=F.relu(self.conv3(x)) #Applying the third convolution and activation\n",
    "        x=self.flatten(x) #Flattening the output from the last convolutional layer\n",
    "        l51=self.fc1(x) #Applying the first fully connected layer\n",
    "        l52=self.fc2(x) #Applying the second fully connected layer\n",
    "        \n",
    "        \n",
    "        return torch.cat((l51,l52),dim=1)  #Concatenating the output from the last two fully connected layers, in case of temperature downscaling\n",
    "    \n",
    "    #Defining the loss function\n",
    "    \n",
    "    def loss (pred,target):\n",
    "        '''Defining the loss function for the model. In this case, the MSE loss is used, also called Gaussian loss, suitable for temperature'''\n",
    "\n",
    "        mean_pred= pred[:, :target.size(1)] #The first half of the output is the mean\n",
    "\n",
    "        return F.mse_loss(mean_pred,target)\n",
    "    \n",
    "\n",
    "    #Writing the training loop\n",
    "\n",
    "    def train_model(model, dataloader, criterion, optimizer, num_epochs=10000, device=device, patience=30):\n",
    "        #Patience : to prevent overfitting in the model, stops the training if loss doesnt improve after 30 epochs\n",
    "        '''Function to train the temperature downscaling model'''\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        #The training loop\n",
    "        best_loss=float('inf')\n",
    "        patience_counter=0\n",
    "\n",
    "\n",
    "        for epoch in range (num_epochs):\n",
    "            model.train()\n",
    "            running_loss=0.0\n",
    "            for inputs, targets in dataloader:\n",
    "                inputs, targets=inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss=criterion(outputs,targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss+=loss.item()*input_size(0)\n",
    "\n",
    "            epoch_loss= running_loss/len(dataloader.dataset)\n",
    "\n",
    "#Implementing early stopping to prevent overfitting\n",
    "            if epoch_loss< best_loss:\n",
    "                best_loss=epoch_loss\n",
    "                patience_counter=0\n",
    "\n",
    "                #Saving the best model\n",
    "                torch.save(model.state_dict(), 'best_model_temp_downscaling.pth')\n",
    "\n",
    "            else:\n",
    "                patience_counter+=1\n",
    "\n",
    "            if patience_counter>patience:\n",
    "                print(f'Early stopping at epoch {epoch+1} with best loss {best_loss}')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
